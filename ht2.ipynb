{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c26ca6b5",
   "metadata": {},
   "source": [
    "# Hoja de Trabajo 2\n",
    "Alina Carías, Daniel Machic y Ariela Mishaan\n",
    "\n",
    "**Github:** https://github.com/ArielaMishaanCohen/HT2.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cfb9b2",
   "metadata": {},
   "source": [
    "## Task 1 - Análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a985078",
   "metadata": {},
   "source": [
    "Considere que usted estádiseñando el sistema de visión para un robot de almacén que debe moverse entre estanterías para recoger productos. El robot tiene dos cámaras frontales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc32606",
   "metadata": {},
   "source": [
    "**Pregunta 1: Durante una prueba, el robot gira sobre su propio eje para escanear el entorno. El ingeniero junior a tu cargo sugiere usar Homografías para medir la distancia a los objetos mientras el robot gira. ¿Es este un enfoque correcto? Justifiquesu respuesta utilizando los conceptos de C1, C2 y Paralaje.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83486ed8",
   "metadata": {},
   "source": [
    "**No**, el enfoque correcto para medir distancia no es la homografía. Cuando el robot solo gira sobre su propio eje, ocurre lo siguiente: \n",
    "\n",
    "- El centro óptico de la cámara en el frame 1 (C1) y en el frame 2 (C2) es el mismo. \n",
    "- No hay traslación, solo rotación. \n",
    "- Como no hay cambio en la posición del centro de proyección, no existe paralaje.\n",
    "\n",
    "La profundidad (Z) se puede estimar cuando existe paralaje, es decir, cuando un punto en el espacio cambia su posición relativa en la imagen debido a un cambio en el punto de vista (C1 ≠ C2). Pero en este caso, C1 = C2. Solo cambia la orientación. No hay desplazamiento lateral de los objetos dependiendo de su profundidad. Por lo tanto, no hay información suficiente para estimar distancia. \n",
    "\n",
    "Una homografía describe la relación entre imágenes cuando la escena es plana o la cámara solo rota. Pero la homografía no permite recuperar profundidad real de objetos en 3D, solo mapea correspondencias entre planos. \n",
    "\n",
    "**Conclusión:** el ingeniero junior está equivocado. Sin traslación no hay paralaje, y sin paralaje no se puede estimar distancia. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5d0e6d",
   "metadata": {},
   "source": [
    "**Si  el  robot  comienza  a  avanzar  (traslación)  y  detectas  que  la  disparidad  (d)  de  una  caja  aumenta repentinamente  entre el  frame  t  y el  frame  t+1,  ¿qué  puedes  inferir sobre  la  distancia  (Z) entre  el robot y la caja? ¿Qué riesgo industrial implicaría un error en el cálculo de esta disparidad?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8641aa",
   "metadata": {},
   "source": [
    "En visión estéreo:\n",
    "\n",
    "$$Z = \\frac{fB}{d}$$\n",
    "\n",
    "Donde: \n",
    "- Z = profundidad\n",
    "- f = distancia total\n",
    "- B = baseline (distancia entre cámaras)\n",
    "- d = disparidad\n",
    "\n",
    "La profundidad es inversamente proporcional a la disparidad. Si la disparidad aumenta, entonces Z disminuye. \n",
    "\n",
    "Si entre el frame t y t+1 la disparidad de la caja aumenta repentinamente, esto significa que: \n",
    "- la caja está más cerca del robot\n",
    "- el robot se está aproximando rápidamente al objeto\n",
    "\n",
    "Si el sistema calcula mal la disparidad, podría estimar una distancia mayor a la real, el robot podría pensar que la caja está lejos y no frenaría a tiempo. El riesgo es que se podría dar colisión con estanterías, daño a mercadería, daño al robot y riesgo para los humanos de alrededor. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cc59e5",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01914fbf",
   "metadata": {},
   "source": [
    "Como director de proyectos, debe asegurar que los modelos de IA quepan en la memoria de los dispositivos (Edge  Computing). Por  ello,  tiene una  imagen  de  entrada  de  alta  resolución  proveniente  de  una  cámara industrial de 1280 x 720 píxeles. Se aplica una capa convolucional con los siguientes hiperparámetros\n",
    "\n",
    "- Tamaño del Filtro (F): 5×5\n",
    "- Padding (P): 2\n",
    "- Stride (S): 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d0f8ef",
   "metadata": {},
   "source": [
    "**Utilizando la fórmula vista en clase, calcule las dimensiones ($W_{out}$,$H_{out}$) del Mapa de Características resultante. Muestra el procedimiento.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747e46f6",
   "metadata": {},
   "source": [
    "Imagen de entrada:\n",
    "\n",
    "$$W_{in} = 1280, H_{in} = 720$$\n",
    "\n",
    "Hiperparámetros:\n",
    "- Filtro F = 5\n",
    "- Padding P = 2\n",
    "- Stride S = 2\n",
    "\n",
    "La fórmula para una convolución es:\n",
    "\n",
    "$$W_{out} = \\lfloor \\frac{W_{in} - F + 2P}{S}\\rfloor + 1$$\n",
    "\n",
    "$$H_{out} = \\lfloor \\frac{H_{in} - F + 2P}{S}\\rfloor + 1$$\n",
    "\n",
    "**Para el ancho:**\n",
    "\n",
    "$$W_{out} = \\lfloor \\frac{1280 - 5 + 2 \\cdot 2}{2}\\rfloor + 1$$\n",
    "\n",
    "$$W_{out} = \\lfloor \\frac{1280 - 5 + 4}{2}\\rfloor + 1$$\n",
    "\n",
    "$$W_{out} = \\lfloor \\frac{1279}{2}\\rfloor + 1$$\n",
    "\n",
    "$$W_{out} = \\lfloor 639.5\\rfloor + 1 = 639 + 1 = \\mathbf{640}$$\n",
    "\n",
    "**Para la altura:**\n",
    "\n",
    "$$H_{out} = \\lfloor \\frac{720 - 5 + 4}{2}\\rfloor + 1$$\n",
    "\n",
    "$$H_{out} = \\lfloor \\frac{719}{2}\\rfloor + 1$$\n",
    "\n",
    "$$H_{out} = \\lfloor 359.5\\rfloor + 1 = 359 + 1 = \\mathbf{360}$$\n",
    "\n",
    "**Dimensiones finales del feature map:** \n",
    "\n",
    "$$W_{out}, H_{out} = (640, 360)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a03ae9",
   "metadata": {},
   "source": [
    "**¿Qué  sucedería  con  el  tamaño  de  la  salida  si  decides  cambiar  el  Padding  a  P=0  (Valid  Padding)? ¿Cómo afectaría esto a la información de los bordes de la imagen (donde suelen estar las referencias de las paredes del almacén)?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65eb0d9a",
   "metadata": {},
   "source": [
    "Si cambiamos el Padding a 0: \n",
    "\n",
    "**Para el ancho:**\n",
    "\n",
    "$$W_{out} = \\lfloor \\frac{1280 - 5 + 0}{2}\\rfloor + 1$$\n",
    "\n",
    "$$W_{out} = \\lfloor \\frac{1275}{2}\\rfloor + 1$$\n",
    "\n",
    "$$W_{out} = \\lfloor 637.5\\rfloor + 1 = 637 + 1 = \\mathbf{638}$$\n",
    "\n",
    "**Para la altura:**\n",
    "\n",
    "$$H_{out} = \\lfloor \\frac{720 - 5 + 0}{2}\\rfloor + 1$$\n",
    "\n",
    "$$H_{out} = \\lfloor \\frac{715}{2}\\rfloor + 1$$\n",
    "\n",
    "$$H_{out} = \\lfloor 357.5\\rfloor + 1 = 357 + 1 = \\mathbf{358}$$\n",
    "\n",
    "**Dimensiones finales del feature map:** \n",
    "\n",
    "$$W_{out}, H_{out} = (638, 358)$$\n",
    "\n",
    "Se puede ver que si el Padding es 0, el kernel no se aplica en los bordes exteriores, eso implica que se pierden los pixeles de alrededor de la imagen y se elimina la información de las orillas. En el contexto del almacén, como las paredes suelen estar en los extremos del campo visual, las referencias de las estructuras (como líneas verticales o esquinas) pueden perderse. El sistema podría detectar peor los límites del pasillo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec311f0e",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647b7cb5",
   "metadata": {},
   "source": [
    "**1. Usted está desarrollando un sistema de detección de griestas microscópicas en motores de avión. ¿Qué combinación de Stride y Pooling recomendaría para no perder detalles críticos en las primeras capas de la red? Justifique técnicamente**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c8a9d1",
   "metadata": {},
   "source": [
    "Recomendación: Stride = 1, sin Max Pooling en las primeras capas. \n",
    "\n",
    "Una grieta miscroscópica puede ocupar, lo más, 2-3 píceles. Si se usa stride = 2 desde el inicio, el filtro salta píxeles y puede perderse exactamente donde está la grieta. Con stride = 1 el filtro recorre cada píxel sin saltar nada. \n",
    "\n",
    "El pooling, en las primeras capas conviene usar Average Pooling o directamente no usar pooling. El Max Pooling descarta todo excepto el valor más alto de una región, lo que puede romper la continuidad de una estructura lineal como una grieta. El Average Pooling suaviza sin tirar información tan agresivamente. \n",
    "\n",
    "En capas más profundas ya se puede ser más agresivo, porque para ese punto la red ya estrajo los patrones relevantes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09cf904",
   "metadata": {},
   "source": [
    "**2. Un cliente le pide que el sistema funcione en un procesador muy limitado (como una cámara inteligente con poca RAM). Explique cómo podrías utilizar el Stride y Max Pooling estratégicamente para reducir la carfa computacional sin eliminar las características más fuertes (activaciones) del Mapa de Características.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5d905b",
   "metadata": {},
   "source": [
    "Recomendación: Stride = 2 + Max Pooling desde capas tempranas\n",
    "\n",
    "El problema con poca RAM es que los feature maps consumen mucha memoria. Con stride = 2 el feature ma´se reduce a la cuarta parte del tamaño original, lo que baja el consumo drásticamente. \n",
    "\n",
    "El Max Pooling es la elección correcta porque aunque reduce el tamaño, conserva las activaciones más fuertes de cada región. Las características importantes (brodes, texturas destacadas) generan activaciones altas que sobreviven al MaxPool, así que no se pierde la información más relevante, solo se descarta lo débil. \n",
    "\n",
    "El tradeoff es que se pierde la precisión espacial (no se sabe dónde está exactamente algo), pero para un sistema de detección simple eso es aceptable. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
